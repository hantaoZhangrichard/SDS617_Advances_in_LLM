{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&DS 617 Applied Machine Learning and Causal Inference Research Seminar: Assignment 1\n",
    "\n",
    "**Deadline**\n",
    "\n",
    "Assignment 1 is due Monday, February 24th at 1:30pm. Late work will not be accepted. \n",
    "\n",
    "**Submission**\n",
    "\n",
    "Submit your assignment as a .pdf on Gradescope. On Gradescope, there are 2 assignments, one where you will submit a pdf file and one where you will submit the corresponding .ipynb that generated it. \n",
    "Note: The problems in each homework assignment are numbered. When submitting the pdf on Gradescope, please select the correct pages that correspond to each problem. \n",
    "\n",
    "To produce the .pdf, do the following to preserve the cell structure of the notebook:\n",
    "- Go to \"File\" at the top-left of your Jupyter Notebook\n",
    "- Under \"Download as\", select \"HTML (.html)\"\n",
    "- After the .html has downloaded, open it and then select \"File\" and \"Print\"\n",
    "- From the print window, select the option to save as a .pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Comparing BERT vs. GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) In this assignment, we will compare BERT (Bidirectional Encoder Representations from Transformers) with GPT (Generative Pre-training Transformer). Provide detailed explanations of how the architecture, the type of attention mechanism employed, and the approach to tokenization in each model contribute to their respective capabilities and applications. Which model do you think will perform better at sentiment analysis and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) We will now perform sentiment analysis on the IMDb dataset (\"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"). This dataset contains movie reviews along with their associated binary sentiment polarity labels. Code has been provided to you below to train and evaluate BERT. \n",
    "\n",
    "Run the below code to get the test accuracy. Then, modify the code to try getting a higher test accuracy (e.g., adjusting hyperparameters, further model tweaking, data augmentation, etc.). Specify what you modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the IMDb dataset\n",
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "# Send a GET request to download the content of the dataset\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # This will raise an exception if there was a download issue\n",
    "\n",
    "# Open the downloaded content as a file-like object\n",
    "file_like_object = BytesIO(response.content)\n",
    "\n",
    "# Extract the tar.gz file\n",
    "with tarfile.open(fileobj=file_like_object) as tar:\n",
    "    tar.extractall(path=\".\")  # Extract to a directory named aclImdb in the current working directory\n",
    "\n",
    "print(\"Dataset downloaded and extracted to './aclImdb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imdb_dataset(directory):\n",
    "    reviews = []\n",
    "    sentiments = []\n",
    "\n",
    "    for sentiment in [\"pos\", \"neg\"]:\n",
    "        dir_name = os.path.join(directory, sentiment)\n",
    "        for filename in os.listdir(dir_name):\n",
    "            if filename.endswith('.txt'):\n",
    "                with open(os.path.join(dir_name, filename), encoding='utf-8') as file:\n",
    "                    reviews.append(file.read())\n",
    "                    sentiments.append(sentiment)\n",
    "\n",
    "    return pd.DataFrame({'review': reviews, 'sentiment': sentiments})\n",
    "\n",
    "# Load the training dataset\n",
    "dataset_dir = 'aclImdb'\n",
    "df_tr = load_imdb_dataset(os.path.join(dataset_dir, 'train'))\n",
    "\n",
    "# Load the test dataset\n",
    "df_te = load_imdb_dataset(os.path.join(dataset_dir, 'test'))\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df_tr.head())\n",
    "print(df_te.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample train and test sets down (note: you may change the size of training) \n",
    "df_tr = df_tr.sample(n=1000, random_state=928)\n",
    "print(df_tr.shape) # check dimensions\n",
    "df_te = df_te.sample(n=500, random_state=2755)\n",
    "print(df_te.shape) # check dimensions\n",
    "df_te.iloc[1, 0] # sample movie review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train BERT (Note: this may take a considerable amount of time. You may modify the size of training if too computationally intensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Function to tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Load the dataset (assuming df_tr is your loaded DataFrame)\n",
    "texts = df_tr['review'].tolist()\n",
    "labels = df_tr['sentiment'].apply(lambda x: 1 if x == 'pos' else 0).tolist()\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the data\n",
    "ml = 128\n",
    "tokenized_dataset = tokenizer(texts, padding=True, truncation=True, max_length=ml)\n",
    "\n",
    "# Splitting the dataset into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_masks, val_masks, train_labels, val_labels = train_test_split(\n",
    "    tokenized_dataset['input_ids'], tokenized_dataset['attention_mask'], labels, test_size=0.2\n",
    ")\n",
    "\n",
    "# Creating dataset objects for training and validation\n",
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = IMDbDataset({'input_ids': train_texts, 'attention_mask': train_masks}, train_labels)\n",
    "val_dataset = IMDbDataset({'input_ids': val_texts, 'attention_mask': val_masks}, val_labels)\n",
    "\n",
    "# Load BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",  # Ensure models are saved at each epoch\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate at each epoch\n",
    "    optim=\"adamw_torch\",  # Use the recommended optimizer\n",
    ")\n",
    "\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "predictions = trainer.predict(val_dataset)\n",
    "val_accuracy = accuracy_score(val_labels, predictions.predictions.argmax(-1))\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = df_te['review'].tolist()\n",
    "test_labels = df_te['sentiment'].apply(lambda x: 1 if x == 'pos' else 0).tolist()\n",
    "\n",
    "# Tokenize the test data\n",
    "test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=ml)\n",
    "\n",
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = {key: torch.tensor(val) for key, val in encodings.items()}\n",
    "        self.labels = torch.tensor(labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]  \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "test_dataset = IMDbDataset(test_encodings, test_labels)\n",
    "\n",
    "# Predictions\n",
    "test_predictions = trainer.predict(test_dataset)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions.predictions.argmax(-1))\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Perform sentiment analysis using GPT-3.5-turbo, gpt-4o, o1-mini, and o3-mini and get the test accuracy. Evaluate their performance by comparing test accuracies. (If you get a rate limit error, just use 4o)\n",
    "\n",
    "**Note: DO NOT try to run advanced models on the entire test set initially.** Be mindful of API usage limits and costs associated with the advanced models APIs. Start with a smaller subset of your test set to ensure your implementation is correct before scaling up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) For the task of language translation, do you expect BERT or GPT to perform better? Explain why in detail. Additionally, discuss the primary challenges associated with implementing each model for translation tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sds617",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
