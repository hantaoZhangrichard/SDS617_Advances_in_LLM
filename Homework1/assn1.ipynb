{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&DS 617 Applied Machine Learning and Causal Inference Research Seminar: Assignment 1\n",
    "\n",
    "**Deadline**\n",
    "\n",
    "Assignment 1 is due Monday, February 24th at 1:30pm. Late work will not be accepted. \n",
    "\n",
    "**Submission**\n",
    "\n",
    "Submit your assignment as a .pdf on Gradescope. On Gradescope, there are 2 assignments, one where you will submit a pdf file and one where you will submit the corresponding .ipynb that generated it. \n",
    "Note: The problems in each homework assignment are numbered. When submitting the pdf on Gradescope, please select the correct pages that correspond to each problem. \n",
    "\n",
    "To produce the .pdf, do the following to preserve the cell structure of the notebook:\n",
    "- Go to \"File\" at the top-left of your Jupyter Notebook\n",
    "- Under \"Download as\", select \"HTML (.html)\"\n",
    "- After the .html has downloaded, open it and then select \"File\" and \"Print\"\n",
    "- From the print window, select the option to save as a .pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Comparing BERT vs. GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) In this assignment, we will compare BERT (Bidirectional Encoder Representations from Transformers) with GPT (Generative Pre-training Transformer). Provide detailed explanations of how the architecture, the type of attention mechanism employed, and the approach to tokenization in each model contribute to their respective capabilities and applications. Which model do you think will perform better at sentiment analysis and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BERT Architecture:\n",
    "BERT only takes the encoder part of the whole encoder-decoder tranformer model. It takes the bidirectioinal attention mechanism such that each token attends to all other tokens in the sentence. The training objective is to predict the masked word in a sentence and classify the true next sentence\n",
    "\n",
    "* BERT tokenization:\n",
    "BERT utilizes the WordPiece algorithm which begins with a base vocabulary of characters and iteratively merges the most frequent pairs of characters or subwords to create new tokens. This approach allows the tokenizer to break down words into smaller pieces, which is particularly useful for handling out-of-vocabulary (OOV) words and learning an embedding representation\n",
    "\n",
    "\n",
    "- GPT Architecture:\n",
    "GPT takes the decoder part of the whole encoder-decoder tranformer model and it runs autoregressively. GPT uses a causal attention mechanism such that future words are masked during the training and the training objective is to predict the next token\n",
    "\n",
    "* GPT tokenization:\n",
    "GPT utilizes Byte-Pair Encoding (BPE), which iteratively merges frequent character pairs. This appraoch helps generate coherent text that makes sense in a chat scenario\n",
    "\n",
    "- Sentiment analysis:\n",
    "I think BERT is likely to perform better at sentiment analysis because sentiment analysis requires understanding the entire sentence to interpret meaning. Sentiment analysis can be seen as a classification task so there is no need to generate logical sentence as output. By training on masked word objective and using bidirectional attention mechanism, BERT can learn a good embedding representation that encodes strong semantic understanding. This can better help understanding the entire sentence and interpret the mearning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) We will now perform sentiment analysis on the IMDb dataset (\"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"). This dataset contains movie reviews along with their associated binary sentiment polarity labels. Code has been provided to you below to train and evaluate BERT. \n",
    "\n",
    "Run the below code to get the test accuracy. Then, modify the code to try getting a higher test accuracy (e.g., adjusting hyperparameters, further model tweaking, data augmentation, etc.). Specify what you modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded and extracted to './aclImdb\n"
     ]
    }
   ],
   "source": [
    "# URL of the IMDb dataset\n",
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "# Send a GET request to download the content of the dataset\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # This will raise an exception if there was a download issue\n",
    "\n",
    "# Open the downloaded content as a file-like object\n",
    "file_like_object = BytesIO(response.content)\n",
    "\n",
    "# Extract the tar.gz file\n",
    "with tarfile.open(fileobj=file_like_object) as tar:\n",
    "    tar.extractall(path=\".\")  # Extract to a directory named aclImdb in the current working directory\n",
    "\n",
    "print(\"Dataset downloaded and extracted to './aclImdb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  For a movie that gets no respect there sure ar...       pos\n",
      "1  Bizarre horror movie filled with famous faces ...       pos\n",
      "2  A solid, if unremarkable film. Matthau, as Ein...       pos\n",
      "3  It's a strange feeling to sit alone in a theat...       pos\n",
      "4  You probably all already know this by now, but...       pos\n",
      "                                              review sentiment\n",
      "0  Based on an actual story, John Boorman shows t...       pos\n",
      "1  This is a gem. As a Film Four production - the...       pos\n",
      "2  I really like this show. It has drama, romance...       pos\n",
      "3  This is the best 3-D experience Disney has at ...       pos\n",
      "4  Of the Korean movies I've seen, only three had...       pos\n"
     ]
    }
   ],
   "source": [
    "def load_imdb_dataset(directory):\n",
    "    reviews = []\n",
    "    sentiments = []\n",
    "\n",
    "    for sentiment in [\"pos\", \"neg\"]:\n",
    "        dir_name = os.path.join(directory, sentiment)\n",
    "        for filename in os.listdir(dir_name):\n",
    "            if filename.endswith('.txt'):\n",
    "                with open(os.path.join(dir_name, filename), encoding='utf-8') as file:\n",
    "                    reviews.append(file.read())\n",
    "                    sentiments.append(sentiment)\n",
    "\n",
    "    return pd.DataFrame({'review': reviews, 'sentiment': sentiments})\n",
    "\n",
    "# Load the training dataset\n",
    "dataset_dir = 'aclImdb'\n",
    "df_tr = load_imdb_dataset(os.path.join(dataset_dir, 'train'))\n",
    "\n",
    "# Load the test dataset\n",
    "df_te = load_imdb_dataset(os.path.join(dataset_dir, 'test'))\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df_tr.head())\n",
    "print(df_te.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "(500, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ok let\\'s start with saying that when a dutch movie is bad, it\\'s REALLY BAD. Rarely something with a little bit of quality comes along(Lek, Karakter) here in holland but not often. Costa! is about 4 girls going to Spain to go on vacation, party, get drunk, get laid (u know the drill). It\\'s also about the world of Clubbers or Proppers. Pro\\'s who\\'re trying to lure the crowd into their club.<br /><br />I\\'m not sure how long it took to write the script, but i suspect somewhere between 15 minutes and 20 minutes because you\\'re watching a bunch of random scenes for 90 minutes long. Nothing, and i mean nothing is believable in this movie. It\\'s almost too riduculous for words what happens with the storyline. Suddenly the movie transforms into a sort of karate action thing. With a one-on-one fight with \\'the bad guy in black\\' and cliche car chase scenes trough a watertank-car (can it be more cheesy). Also the words character-development and casting are unfamiliar to the makers.<br /><br />After having seen \"Traffic\" 3 days before this, i fell from sheer brilliance, from a piece of art to this. This is film-making at it\\'s saddest. And don\\'t start about low budget. Because even with a low budget you could write a better script. It almost seems that the film-makers were too busy partying themselves to make a decent movie.<br /><br />Anyway the chicks in the water at the end made it up a little bit, but for the rest of it, don\\'t waste your money on such garbage.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subsample train and test sets down (note: you may change the size of training) \n",
    "df_tr = df_tr.sample(n=1000, random_state=928)\n",
    "print(df_tr.shape) # check dimensions\n",
    "df_te = df_te.sample(n=500, random_state=2755)\n",
    "print(df_te.shape) # check dimensions\n",
    "df_te.iloc[1, 0] # sample movie review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train BERT (Note: this may take a considerable amount of time. You may modify the size of training if too computationally intensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/zhanghantao/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 02:27, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.676539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.647200</td>\n",
       "      <td>0.643153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.588600</td>\n",
       "      <td>0.568931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.483761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.418190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=125, training_loss=0.5667090435028076, metrics={'train_runtime': 148.9392, 'train_samples_per_second': 26.857, 'train_steps_per_second': 0.839, 'total_flos': 263111055360000.0, 'train_loss': 0.5667090435028076, 'epoch': 5.0})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Function to tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Load the dataset (assuming df_tr is your loaded DataFrame)\n",
    "texts = df_tr['review'].tolist()\n",
    "labels = df_tr['sentiment'].apply(lambda x: 1 if x == 'pos' else 0).tolist()\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the data\n",
    "ml = 128\n",
    "tokenized_dataset = tokenizer(texts, padding=True, truncation=True, max_length=ml)\n",
    "\n",
    "# Splitting the dataset into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_masks, val_masks, train_labels, val_labels = train_test_split(\n",
    "    tokenized_dataset['input_ids'], tokenized_dataset['attention_mask'], labels, test_size=0.2\n",
    ")\n",
    "\n",
    "# Creating dataset objects for training and validation\n",
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = IMDbDataset({'input_ids': train_texts, 'attention_mask': train_masks}, train_labels)\n",
    "val_dataset = IMDbDataset({'input_ids': val_texts, 'attention_mask': val_masks}, val_labels)\n",
    "\n",
    "# Load BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",  # Ensure models are saved at each epoch\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate at each epoch\n",
    "    optim=\"adamw_torch\",  # Use the recommended optimizer\n",
    ")\n",
    "\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "predictions = trainer.predict(val_dataset)\n",
    "val_accuracy = accuracy_score(val_labels, predictions.predictions.argmax(-1))\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.832\n"
     ]
    }
   ],
   "source": [
    "test_texts = df_te['review'].tolist()\n",
    "test_labels = df_te['sentiment'].apply(lambda x: 1 if x == 'pos' else 0).tolist()\n",
    "\n",
    "# Tokenize the test data\n",
    "test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=ml)\n",
    "\n",
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = {key: torch.tensor(val) for key, val in encodings.items()}\n",
    "        self.labels = torch.tensor(labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]  \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "test_dataset = IMDbDataset(test_encodings, test_labels)\n",
    "\n",
    "# Predictions\n",
    "test_predictions = trainer.predict(test_dataset)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions.predictions.argmax(-1))\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Perform sentiment analysis using GPT-3.5-turbo, gpt-4o, o1-mini, and o3-mini and get the test accuracy. Evaluate their performance by comparing test accuracies. (If you get a rate limit error, just use 4o)\n",
    "\n",
    "**Note: DO NOT try to run advanced models on the entire test set initially.** Be mindful of API usage limits and costs associated with the advanced models APIs. Start with a smaller subset of your test set to ensure your implementation is correct before scaling up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "<class 'int'>\n",
      "OpenAI API Key loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(len(test_texts))\n",
    "print(type(test_labels[0]))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Use the API key\n",
    "if openai_api_key:\n",
    "    print(\"OpenAI API Key loaded successfully!\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not found. Please check your .env file.\")\n",
    "\n",
    "client = openai.OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def test_sentiment(model_name):\n",
    "    result = []\n",
    "\n",
    "    initial_prompt = \"\"\"You will be given a paragraph of movie review that is either positive or negative. Please tell me whether it is positive or negative \\n\n",
    "                        If it is positive, respond 1. If it is negative, respond 0. Please only give 0 or 1 in your response\"\"\"\n",
    "\n",
    "    for i in range(len(test_texts)):\n",
    "        # Make a chat completion request\n",
    "        if i % 50 == 0:\n",
    "            print(i)\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": initial_prompt,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": test_texts[i],\n",
    "                }\n",
    "            ],\n",
    "            model=model_name,  # Specify the model\n",
    "        )\n",
    "\n",
    "        # Access the response content using attributes\n",
    "        response_content = chat_completion.choices[0].message.content\n",
    "        try:\n",
    "            result.append(int(response_content))\n",
    "        except:\n",
    "            print(response_content)\n",
    "            result.append(response_content)\n",
    "\n",
    "    # print(result)\n",
    "    with open(f\"{model_name}.json\", \"w\") as f:\n",
    "        json.dump(result, f)\n",
    "    # print(test_labels[1:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "model_list = [\"gpt-3.5-turbo\", \"gpt-4o\"]  # , \"o1-mini\", \"o3-mini\"]\n",
    "\n",
    "for model in model_list:\n",
    "    test_sentiment(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for gpt-3.5-turbo: 0.952\n",
      "[0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "Test Accuracy for gpt-4o: 0.95\n",
      "[0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "model_list = [\"gpt-3.5-turbo\", \"gpt-4o\"]\n",
    "for model in model_list:\n",
    "    with open(f\"{model}.json\", 'r') as file:\n",
    "        data = json.load(file)\n",
    "        test_accuracy = accuracy_score(test_labels, data)\n",
    "        print(f\"Test Accuracy for {model}: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) For the task of language translation, do you expect BERT or GPT to perform better? Explain why in detail. Additionally, discuss the primary challenges associated with implementing each model for translation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I expect GPT to perform better because unlike classification, translation task requires to generate sentences that can be understood by human-beings. GPT has a causal attention mechanism which allows it to generate coherant sentences and if we prompt the model with untranslated sentences, the self attention mechanism can address long-range dependencies without losing memories while generating translation autoregressively.\n",
    "* Challenges for BERT: since it has no decoder, it would be hard for us to design a decoder to turn its output into translation. Also, it is not trained using causal attention autoregressively, it struggles to generate understandable sentences even though it may learn a good embeddings. \n",
    "- Challenges for GPT: because of the autoregressive nature, mistakes in early stages will propagate to later stages, causing inaccuracies and hallucinations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
